{
 "metadata": {
  "name": "IntroMCMC"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<style>\n",
      "    @font-face {\n",
      "        font-family: \"Computer Modern\";\n",
      "        src: url('http://mirrors.ctan.org/fonts/cm-unicode/fonts/otf/cmunss.otf');\n",
      "    }\n",
      "    div.cell{\n",
      "        width:800px;\n",
      "        margin-left:auto;\n",
      "        margin-right:auto;\n",
      "    }\n",
      "    h1 {\n",
      "        text-align:center;\n",
      "        font-family:\"Charis SIL\", serif;\n",
      "    }\n",
      "    div.text_cell_render{\n",
      "        font-family: Computer Modern, \"Helvetica Neue\", Arial, Helvetica, Geneva, sans-serif;\n",
      "        line-height: 145%;\n",
      "        font-size: 120%;\n",
      "        width:800px;\n",
      "        margin-left:auto;\n",
      "        margin-right:auto;\n",
      "    }\n",
      "    .CodeMirror{\n",
      "            font-family: Consolas, monospace;\n",
      "    }\n",
      "    .prompt{\n",
      "        display: None;\n",
      "    }\n",
      "</style>\n",
      "<script>\n",
      "    MathJax.Hub.Config({\n",
      "                        TeX: {\n",
      "                           extensions: [\"AMSmath.js\"]\n",
      "                           },\n",
      "                tex2jax: {\n",
      "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
      "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
      "                },\n",
      "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
      "                \"HTML-CSS\": {\n",
      "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
      "                }\n",
      "        });\n",
      "</script>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize( 12, 4 )\n",
      "import scipy.stats as stats"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This should be a brief intro to what MCMC is, framed in words like *convergence*, *iterations*, *being fit to the data*, *learning*. The chapter should introduce:\n",
      "\n",
      "- MCMC convergence + some diagnogstics\n",
      "- Matplot.plot\n",
      "- MAP (and how to estimate it) (maybe move this to another section)\n",
      "- mcmc.sample()\n",
      "- mcmc.trace() use\n",
      "- map.fit()\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Chapter 3\n",
      "\n",
      "\n",
      "_______\n",
      "\n",
      "## Opening the black box of MCMC"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The previous two chapters hide the inner-mechanics of PyMC, and Monte Carlo Markov Chains (MCMC) more generally, from the reader. This was not a slight against the reader's intelligence. Simpley, it is not absolutely necessary to know. After all, my computer has an internal kernel, compiler, and RAM that I haven't the slightest idea how they work. But I can still work on my computer just fine. \n",
      "\n",
      "The reason for including this chapter is three-fold. The first is that any book on Bayesian inference must discuss MCMC. I cannot fight this. Blame the statisticians. Secondly, knowing the process of MCMC gives you insight into whether your algorithm has converged. (Converged to what? We will get to that) Thirdly, we understand *why* we receive samples from the positerior as a result, which is quite a strange result at first. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "_____\n",
      "### Example: Poisson Regression\n",
      "\n",
      "Perhaps the most important result from medical research was the *now obvious* link between *smoking and cancer*. We'll try to establish a link using Bayesian methods. We have a decision here: should we include a prior that biases us towards there existing a significant link between smoking and cancer? I think we should act like scientists at the turn of the century, and assume there's is no *a priori* reason to assume a link. \n",
      "\n",
      "The dataset we will be using contains 36 cohorts (a unique group with a larger population), each cohort has variables:\n",
      "\n",
      "-  age: in five-year age groups coded 1 to 9 for 40-44, 45-49, 50-54, 55-59, 60-64, 65-69, 70-74, 75-79, 80+.\n",
      "-  cigar/pipe smoking status: 1 if the cohort only smokes cigars/pipes, 0 else.\n",
      "-  cigar & cigarette smoking status: 1 if the cohort smoke *both* cigars/pipes and cigarettes, 0 else.\n",
      "-  cigarette smoking status: 1 if the cohort only smoke cigarettes, 0 else.\n",
      "-  population: the population, in hundreds of thousands, of the age group *and* smoking status cohort. Denote this $P_i$.\n",
      "- deaths: number of lung cancer deaths in the of the specfic cohort over the course of a year . Denote this $D_i$.\n",
      "\n",
      "\n",
      "As $D_i$ is count data, a Poisson random variable would be appropriate to model it. \n",
      "\n",
      "$$D_i \\sim \\text{Poi}(\\lambda_i )$$\n",
      "\n",
      "Of course, we don't know $\\lambda_i$, but we can hypothesize that it is a function the age and smoking status.  The simplest way to connect $\\lambda_i$ and cohort variables age and smoking statuses (not population), denoted $\\mathbb{x}_i$, is with a link function:\n",
      "\n",
      "\n",
      "$$\\lambda_i = P_i\\exp \\left( \\beta^T \\mathbb{x_i} \\right) $$\n",
      "\n",
      "where $\\beta$ are coefficients to be determined. We require the $\\exp \\;$ link function because the linear combination of variables may be negative, but we require the number of deaths to be positive.\n",
      "\n",
      "Why did we put the $P_i$ in front of the exponential? This seperates the *rate of deaths*, given variables $\\mathbb{x}_i$ and represented by the exponential term, and the *number of expected deaths*, represented on the left-hand side. A larger population will naturally have more deaths, independent of the age and smoking statuses, so we need to account for this. Suppose the exponential term is 0.01, and the population is 10,000, the the expected number of deaths is  $10,000 \\times 0.001 = 10$. Another way to see this is show the equivalent form:\n",
      "\n",
      "$$\\frac{\\lambda_i}{P_i} = \\exp \\left( \\beta^T \\mathbb{x_i} \\right) $$\n",
      "\n",
      "where the left hand side is the expected number of deaths over the cohort's population (which is a rate), and the right hand side is an estimate of the rate (given we know $\\beta_i$'s ). With respect to the original form, we can rewrite this as:\n",
      "\n",
      "$$\\lambda_i = \\exp \\left( \\beta^T \\mathbb{x_i} + \\log{P_i} \\right) $$\n",
      "\n",
      "which is what more statisticians do. This is also called *adding an offset term*. \n",
      "\n",
      "This example is quite different from our last example on text-messaging rates, though the two look similar. We are not trying to estimate a *global* $\\lambda$, that is a single parameter $\\lambda$ that determines the distributions of all the observations, but we are actual trying to model a unique $\\lambda$ for each data point using the observed variables, i.e. $\\lambda_i = f( \\mathbf{x}_i, P_i, \\beta )$. to your model.\n",
      "\n",
      "\n",
      "Our conclusions are determined by the posterior distributions of $\\beta_1, \\beta_2$ and $\\beta_3$. If the distributions are shifted to be positive, then a 1 in a smoking status will shift the $\\lambda_i$ forward, resulting in an increase in the number of deaths. Our task in now to find the posteriors of $\\beta_i$. We first need a prior for the $\\beta$s: the most natural being Normal distributions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pymc as mc\n",
      "\n",
      "data = np.genfromtxt( \"chp2data/smoking_death.csv\", skip_header = 1,\n",
      "             delimiter=\",\", dtype = float )\n",
      "\n",
      "population = data[:,-2].copy()\n",
      "deaths = data[:,-1].copy()\n",
      "data[:,-2] = 1 #replace the last column with a constant to represent beta_0\n",
      "data = data[:,:-1]\n",
      "\n",
      "#Instead of creating variable beta_1, beta_2, etc., \n",
      "beta = mc.MvNormal( \"beta_coefs\", mu = np.zeros(5) , \\\n",
      "    tau = 0.0001*np.identity(5), value = np.zeros(5))\n",
      "print \"initial beta.value = \", beta.value\n",
      "\n",
      "#we'll create a deterministic function that represents the exponential \n",
      "#of a linear combination\n",
      "@mc.deterministic\n",
      "def exp_lin_comb( beta = beta ):\n",
      "    return np.exp( np.dot( data, beta ) + np.log(population)  )\n",
      "\n",
      "observations = mc.Poisson( \"obs\", exp_lin_comb, value = deaths, observed = True )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IOError",
       "evalue": "chp2data/smoking_death.csv not found.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mIOError\u001b[0m                                   Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-1-aadb786d8721>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m data = np.genfromtxt( \"chp2data/smoking_death.csv\", skip_header = 1,\n\u001b[1;32m----> 4\u001b[1;33m              delimiter=\",\", dtype = float )\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mpopulation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Python27\\lib\\site-packages\\numpy\\lib\\npyio.pyc\u001b[0m in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skiprows, skip_header, skip_footer, converters, missing, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1272\u001b[1;33m             \u001b[0mfhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rbU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1273\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Python27\\lib\\site-packages\\numpy\\lib\\_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(path, mode, destpath)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mc:\\Python27\\lib\\site-packages\\numpy\\lib\\_datasource.pyc\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, path, mode)\u001b[0m\n\u001b[0;32m    477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0m_file_openers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mext\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    478\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 479\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s not found.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mIOError\u001b[0m: chp2data/smoking_death.csv not found."
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = mc.Model( [observations, beta, exp_lin_comb] )\n",
      "\n",
      "\n",
      "\n",
      "#mysterious code to be explained in Chapter 3\n",
      "map_ = mc.MAP( model )\n",
      "map_.fit()\n",
      "mcmc = mc.MCMC( model )\n",
      "mcmc.sample( 350000, 300000, 2 ) #TODO reduce"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(12.5, 10)\n",
      "#histogram of the samples:\n",
      "plt.figure()\n",
      "\n",
      "beta_samples = mcmc.trace(\"beta_coefs\")[:]\n",
      "\n",
      "plt.subplot(311)\n",
      "plt.title( r\"Positerior distributions of $\\beta_1, \\beta_2, \\beta_3$\" )\n",
      "plt.hist( beta_samples[:, 1],histtype='stepfilled', bins = 50, alpha = 0.85, \\\n",
      "        label = r\"positerior of $\\beta_1$\", color = \"#A60628\",normed = True  )\n",
      "plt.legend()\n",
      "\n",
      "plt.subplot(312)\n",
      "plt.hist( beta_samples[:, 2], histtype='stepfilled', bins = 50, alpha = 0.85, \\\n",
      "        label = r\"positerior of $\\beta_2$\", color = \"#7A68A6\",normed = True)\n",
      "plt.legend()\n",
      "\n",
      "plt.subplot(313)\n",
      "plt.hist( beta_samples[:, 3], bins = 50, alpha = 0.85, \n",
      "        label = r\"positerior of $\\beta_3$\", \\\n",
      "         color=\"#467821\", normed = True, histtype='stepfilled' )\n",
      "plt.legend()\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What can we say? It looks like all positerior distributions of $\\beta$ are strictly positive. This implies strong evidence that smoking increases the number of deaths in a population, since if a smoking status is equal to 1 and $\\beta$ is positive the following term will increase:\n",
      "\n",
      "$$\\lambda_i = P_i\\exp \\left( \\beta^T \\mathbb{x_i} \\right) $$\n",
      "\n",
      "leading to an increase in the expected number of deaths. \n",
      "\n",
      "Let's perform some prediction. As we modeled the parameter $\\lambda_i$ in a Poisson distribution, we can find the *expected rate* of deaths. We are taking the average over the posterior distributions:\n",
      "\n",
      "> We compute `np.dot( data, beta_samples.T )`. This produces a very large matrix which is each posterior sample multiplied with the each data:\n",
      "\n",
      "$$\\beta_j^T x_i, \\;\\; \\text{ for all $i$, for all $j$} $$\n",
      "\n",
      "> we then exponentiate this matrix and take the mean over all $j$ (over the posterior samples). So we are left with the a good estimate of the expected rate of deaths per population group $x_i$. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize(12.5, 7)\n",
      "rates = np.mean( np.exp( np.dot( data, beta_samples.T ) ), axis = 1 )\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\"]\n",
      "labels = [\"does not smoke\", \n",
      "          \"only cigars/pipes\",\n",
      "          \"both cigarettes & cigars/pipes\", \n",
      "          \"only cigarettes\"]\n",
      "\n",
      "for i in range(4):\n",
      "    plt.plot( 40 + 5*data[9*i:9*(i+1),0], rates[9*i:9*(i+1)], marker = 'o', \n",
      "         color = colors[i], label = labels[i], lw=1)\n",
      "    \n",
      "plt.legend(loc=\"upper left\")\n",
      "plt.xlabel( \"age\" )\n",
      "plt.ylabel(\"expected death rate (deaths/population)\" )\n",
      "plt.title( \"Expected deaths rate; partitioned by smoking habits\")\n",
      "plt.xlim( 42, 87 )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'data' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-2-df564b560c39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mrates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta_samples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"#348ABD\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#A60628\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#7A68A6\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#467821\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m labels = [\"does not smoke\", \n",
        "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Clearly** smoking affects how long you live. \n",
      "\n",
      "We can interpret these rates are probabilities, for example, 0.032 is the rate of a non-smokers dying at age 40, which is equilivant to the probablity of a randomly selected non-smoker aged 40-45 will die. Hence  1- 0.032 = 0.968 is the probability he/she survives to 45. Similarly, with probability 0.045 a 45-50 year old non-smoker will survive until age 50. Hence, (1- 0.032)(1 - 0.045) is the probability a non-smoker, aged 40 will survive until 50, and so on. Let's plot this."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "figsize( 12.5, 5 )\n",
      "prob_survival  = 1-rates\n",
      "\n",
      "colors = [\"#348ABD\", \"#A60628\", \"#7A68A6\", \"#467821\"]\n",
      "labels = [\"does not smoke\", \n",
      "          \"only cigars/pipes\",\n",
      "          \"both cigarettes & cigars/pipes\", \n",
      "          \"only cigarettes\"]\n",
      "\n",
      "for i in range(4):\n",
      "    _p = prob_survival[ 9*i:9*(i+1) ].cumprod()\n",
      "    plt.plot( 40 + 5*data[9*i:9*(i+1),0], _p, marker = 'o', \n",
      "         color = colors[i], label = labels[i], lw=1)\n",
      "\n",
      "plt.legend(loc=\"lower left\")\n",
      "plt.xlabel(\"Age\")\n",
      "plt.ylabel(\"Probability of survival\")\n",
      "plt.title(\"Prbability of survival, segmented by smoking\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'rates' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-3-b2e0e7e0ed7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;36m12.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprob_survival\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mrates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcolors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"#348ABD\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#A60628\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#7A68A6\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"#467821\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m labels = [\"does not smoke\", \n",
        "\u001b[1;31mNameError\u001b[0m: name 'rates' is not defined"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears that smoking cigarettes will almost certainly kill you before age 85, whereas not smoking provides you with 15% chances to live this long. So, for you young hackers out there, **which path do you want to take**?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### References\n",
      "\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}